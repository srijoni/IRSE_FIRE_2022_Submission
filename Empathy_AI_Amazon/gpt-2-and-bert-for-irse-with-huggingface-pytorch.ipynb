{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"We have used GPT-2 model in HuggingFace Library. <br>\nWe have refered to following links, [ðŸŽ»Fine-tune Transformers in PyTorch using ðŸ¤— Transformers](https://gmihaila.medium.com/fine-tune-transformers-in-pytorch-using-transformers-57b40450635).\nWe are proposing to use Large pre-trained language model for usefulness of comment prediction.\nThe usefullness of these model is limited need for feature engineering. These models are pretrained on large code bases/textual document and can easily produce superior quality features.\n\nBert/GPT based mdoel also comes with subwork/sentence peiece tokenizer. These tokenizer can easily handle OOV. Also since we are working with code snippet we did'nt do any pre-processing (textual pre-processing won't be useful for code based language)","metadata":{}},{"cell_type":"markdown","source":"### 1. Model and Tokenizer\n\nIn ðŸ¤—, they prepared GPT2 model for classification in advance. Very Thankful! <br>\nHere's link: https://huggingface.co/transformers/model_doc/gpt2.html#transformers.GPT2ForSequenceClassification","metadata":{}},{"cell_type":"code","source":"from transformers import set_seed, GPT2Config, GPT2Tokenizer, GPT2ForSequenceClassification\n\nset_seed(731) \nmodel_config = GPT2Config.from_pretrained('gpt2', num_labels=2) # Binary Classification\nmodel = GPT2ForSequenceClassification.from_pretrained('gpt2', config=model_config)\n\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ntokenizer.padding_side = \"left\" # Very Important\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.config.pad_token_id = model.config.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:05:47.001829Z","iopub.execute_input":"2022-08-07T06:05:47.002191Z","iopub.status.idle":"2022-08-07T06:06:04.960080Z","shell.execute_reply.started":"2022-08-07T06:05:47.002154Z","shell.execute_reply":"2022-08-07T06:06:04.959122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import set_seed, GPT2Config, GPT2Tokenizer, GPT2ForSequenceClassification\n\nset_seed(731) # My Birthday!, you should get train_loss: 0.773, train_acc: 0.567 in epoch 0.\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:06:04.962105Z","iopub.execute_input":"2022-08-07T06:06:04.962722Z","iopub.status.idle":"2022-08-07T06:06:04.968798Z","shell.execute_reply.started":"2022-08-07T06:06:04.962680Z","shell.execute_reply":"2022-08-07T06:06:04.968119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n#pd.read_csv(\"../input/irecdata/IRSE_Test_Data_preprocessed.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-08-18T19:58:12.531890Z","iopub.execute_input":"2022-08-18T19:58:12.532230Z","iopub.status.idle":"2022-08-18T19:58:12.538306Z","shell.execute_reply.started":"2022-08-18T19:58:12.532198Z","shell.execute_reply":"2022-08-18T19:58:12.537414Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"dataPath = \"../input/irecdata/\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Build Dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom torch.utils.data import Dataset\n\nclass TweetDataset(Dataset):\n    def __init__(self, train=True):\n        super().__init__()\n        self.train = train\n        self.data = pd.read_csv(os.path.join(dataPath, 'IRSE_Training_Data_preprocessed.csv' if train else 'IRSE_Test_Data_preprocessed.csv'))\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        record = self.data.iloc[index]\n        text = \"Comment: \" + record['Comments'] + \" code: \"+record['Surrounding Code Context']\n        label = 0 if record['Class'] == 'Not Useful' else 1\n        return {'text': text, 'label': label}\n        \n\ntrain_dataset = TweetDataset(train=True)\ntest_dataset = TweetDataset(train=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-07T06:06:05.035143Z","iopub.execute_input":"2022-08-07T06:06:05.035669Z","iopub.status.idle":"2022-08-07T06:06:05.178942Z","shell.execute_reply.started":"2022-08-07T06:06:05.035629Z","shell.execute_reply":"2022-08-07T06:06:05.178116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    print(train_dataset.__getitem__(i)['text'])","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:06:05.192322Z","iopub.execute_input":"2022-08-07T06:06:05.193004Z","iopub.status.idle":"2022-08-07T06:06:05.206492Z","shell.execute_reply.started":"2022-08-07T06:06:05.192966Z","shell.execute_reply":"2022-08-07T06:06:05.205718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Data Collator","metadata":{}},{"cell_type":"code","source":"class Gpt2ClassificationCollator(object):\n    def __init__(self, tokenizer, max_seq_len=None):\n        self.tokenizer = tokenizer\n        self.max_seq_len = max_seq_len\n        \n        return\n    \n    def __call__(self, sequences):\n        texts = [sequence['text'] for sequence in sequences]\n        labels = [int(sequence['label']) for sequence in sequences]\n        inputs = self.tokenizer(text=texts,\n                                return_tensors='pt',\n                                padding=True,\n                                truncation=True,\n                                max_length=self.max_seq_len)\n        inputs.update({'labels': torch.tensor(labels)})\n        \n        return inputs\n\ngpt2classificationcollator = Gpt2ClassificationCollator(tokenizer=tokenizer,\n                                                        max_seq_len=60)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:06:05.208005Z","iopub.execute_input":"2022-08-07T06:06:05.208624Z","iopub.status.idle":"2022-08-07T06:06:05.216510Z","shell.execute_reply.started":"2022-08-07T06:06:05.208583Z","shell.execute_reply":"2022-08-07T06:06:05.215627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. DataLoader","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\n\ntrain_size = int(len(train_dataset) * 0.8)\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\ntrain_dataloader = DataLoader(dataset=train_dataset,\n                              batch_size=32,\n                              shuffle=True,\n                              collate_fn=gpt2classificationcollator)\nval_dataloader = DataLoader(dataset=val_dataset,\n                            batch_size=32,\n                            shuffle=False,\n                            collate_fn=gpt2classificationcollator)\ntest_dataloader = DataLoader(dataset=test_dataset,\n                             batch_size=32,\n                             shuffle=False,\n                             collate_fn=gpt2classificationcollator)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:06:05.217846Z","iopub.execute_input":"2022-08-07T06:06:05.218443Z","iopub.status.idle":"2022-08-07T06:06:05.231372Z","shell.execute_reply.started":"2022-08-07T06:06:05.218408Z","shell.execute_reply":"2022-08-07T06:06:05.230537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Optimizer & Lr Scheduler","metadata":{}},{"cell_type":"code","source":"from transformers import AdamW, get_cosine_schedule_with_warmup\n\ntotal_epochs = 10\n\nparam_optimizer = list(model.named_parameters())\nno_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\noptimizer_grouped_parameters = [\n    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n]\noptimizer = AdamW(optimizer_grouped_parameters,\n                  lr=1e-5,\n                  eps=1e-8)\n\nnum_train_steps = len(train_dataloader) * total_epochs\nnum_warmup_steps = int(num_train_steps * 0.1) \n\nlr_scheduler = get_cosine_schedule_with_warmup(optimizer,\n                                               num_warmup_steps=num_warmup_steps,\n                                               num_training_steps = num_train_steps)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:06:05.232735Z","iopub.execute_input":"2022-08-07T06:06:05.233434Z","iopub.status.idle":"2022-08-07T06:06:05.247494Z","shell.execute_reply.started":"2022-08-07T06:06:05.233399Z","shell.execute_reply":"2022-08-07T06:06:05.246475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6. Train & Validation","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef train(dataloader, optimizer, scheduler, device_):\n    global model\n    model.train()\n    \n    prediction_labels = []\n    true_labels = []\n    \n    total_loss = []\n    \n    for batch in dataloader:\n        true_labels += batch['labels'].numpy().flatten().tolist()\n        batch = {k:v.type(torch.long).to(device_) for k, v in batch.items()}\n        \n        \n        outputs = model(**batch)\n        loss, logits = outputs[:2]\n        logits = logits.detach().cpu().numpy()\n        total_loss.append(loss.item())\n        \n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # prevent exploding gradient\n\n        optimizer.step()\n        scheduler.step()\n        \n        prediction_labels += logits.argmax(axis=-1).flatten().tolist()\n    \n    return true_labels, prediction_labels, total_loss\n\ndef validation(dataloader, device_):\n    global model\n    model.eval()\n    \n    prediction_labels = []\n    true_labels = []\n    \n    total_loss = []\n    \n    for batch in dataloader:\n        true_labels += batch['labels'].numpy().flatten().tolist()\n        batch = {k:v.type(torch.long).to(device_) for k, v in batch.items()}\n        \n        with torch.no_grad():\n            outputs = model(**batch)\n            loss, logits = outputs[:2]\n            logits = logits.detach().cpu().numpy()\n            total_loss.append(loss.item())\n\n            prediction_labels += logits.argmax(axis=-1).flatten().tolist()\n        \n    return true_labels, prediction_labels, total_loss","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:06:05.249055Z","iopub.execute_input":"2022-08-07T06:06:05.249756Z","iopub.status.idle":"2022-08-07T06:06:05.264135Z","shell.execute_reply.started":"2022-08-07T06:06:05.249715Z","shell.execute_reply":"2022-08-07T06:06:05.263339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7. Run!","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel.to(device)\n\nall_loss = {'train_loss': [], 'val_loss': []}\nall_acc = {'train_acc': [], 'val_acc': []}\n\nfor epoch in range(total_epochs):\n    y, y_pred, train_loss = train(train_dataloader, optimizer, lr_scheduler, device)\n    train_acc = accuracy_score(y, y_pred)\n    \n    y, y_pred, val_loss = validation(val_dataloader, device)\n    val_acc = accuracy_score(y, y_pred)\n    \n    all_loss['train_loss'] += train_loss\n    all_loss['val_loss'] += val_loss\n    \n    all_acc['train_acc'].append(train_acc)\n    all_acc['val_acc'].append(val_acc)\n    \n    print(f'Epoch: {epoch}, train_loss: {torch.tensor(train_loss).mean():.3f}, train_acc: {train_acc:.3f}, val_loss: {torch.tensor(val_loss).mean():.3f}, val_acc: {val_acc:.3f}') ","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:06:05.266877Z","iopub.execute_input":"2022-08-07T06:06:05.267135Z","iopub.status.idle":"2022-08-07T06:16:04.667009Z","shell.execute_reply.started":"2022-08-07T06:06:05.267110Z","shell.execute_reply":"2022-08-07T06:16:04.666144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7.1. Check Loss with Graph","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfig = plt.figure(figsize=(20,20))\na = fig.add_subplot(4, 1, 1)\nb = fig.add_subplot(4, 1, 2)\nc = fig.add_subplot(2, 1, 2)\na.plot(all_loss['train_loss'])\nb.plot(all_loss['val_loss'])\nc.plot(all_acc['train_acc'])\nc.plot(all_acc['val_acc'])\nc.set(xlabel='epoch', ylabel='accuracy')\nc.legend(['train', 'val'])\n\npass","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:16:04.668337Z","iopub.execute_input":"2022-08-07T06:16:04.668848Z","iopub.status.idle":"2022-08-07T06:16:05.228675Z","shell.execute_reply.started":"2022-08-07T06:16:04.668808Z","shell.execute_reply":"2022-08-07T06:16:05.227772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 8. Run on Test Data","metadata":{}},{"cell_type":"code","source":"y, y_pred, val_loss = validation(val_dataloader, device)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:16:05.229760Z","iopub.execute_input":"2022-08-07T06:16:05.230113Z","iopub.status.idle":"2022-08-07T06:16:10.738305Z","shell.execute_reply.started":"2022-08-07T06:16:05.230074Z","shell.execute_reply":"2022-08-07T06:16:10.737415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ntarget_names = ['Not Useful', 'Useful']\nprint(classification_report(y, y_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:16:10.739735Z","iopub.execute_input":"2022-08-07T06:16:10.740078Z","iopub.status.idle":"2022-08-07T06:16:10.753963Z","shell.execute_reply.started":"2022-08-07T06:16:10.740041Z","shell.execute_reply":"2022-08-07T06:16:10.753091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y, y_pred, val_loss = validation(test_dataloader, device)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:16:10.756969Z","iopub.execute_input":"2022-08-07T06:16:10.757271Z","iopub.status.idle":"2022-08-07T06:16:14.426532Z","shell.execute_reply.started":"2022-08-07T06:16:10.757246Z","shell.execute_reply":"2022-08-07T06:16:14.425781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ntarget_names = ['Not Useful', 'Useful']\nprint(classification_report(y, y_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:16:14.427799Z","iopub.execute_input":"2022-08-07T06:16:14.428153Z","iopub.status.idle":"2022-08-07T06:16:14.441044Z","shell.execute_reply.started":"2022-08-07T06:16:14.428104Z","shell.execute_reply":"2022-08-07T06:16:14.440116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, y_pred, _ = validation(test_dataloader, device)\n\nsubmit = pd.read_csv(dataPath+'IRSE_Test_Data_preprocessed.csv')\nsubmit['target'] = y_pred\n\nsubmit.to_csv('IRSE_Test_Data_preprocessed_GPT.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:16:14.442906Z","iopub.execute_input":"2022-08-07T06:16:14.443276Z","iopub.status.idle":"2022-08-07T06:16:18.496890Z","shell.execute_reply.started":"2022-08-07T06:16:14.443240Z","shell.execute_reply":"2022-08-07T06:16:18.496136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"gpt-2_model\")","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:16:18.498256Z","iopub.execute_input":"2022-08-07T06:16:18.498580Z","iopub.status.idle":"2022-08-07T06:16:20.282487Z","shell.execute_reply.started":"2022-08-07T06:16:18.498547Z","shell.execute_reply":"2022-08-07T06:16:20.281655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bert based model for Baseline","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForNextSentencePrediction\nimport torch\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:21:58.749735Z","iopub.execute_input":"2022-08-07T06:21:58.750088Z","iopub.status.idle":"2022-08-07T06:21:58.754310Z","shell.execute_reply.started":"2022-08-07T06:21:58.750052Z","shell.execute_reply":"2022-08-07T06:21:58.753244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:21:59.840410Z","iopub.execute_input":"2022-08-07T06:21:59.840724Z","iopub.status.idle":"2022-08-07T06:22:04.381163Z","shell.execute_reply.started":"2022-08-07T06:21:59.840694Z","shell.execute_reply":"2022-08-07T06:22:04.380153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom torch.utils.data import Dataset\n\nclass TweetDataset(Dataset):\n    def __init__(self, train=True):\n        super().__init__()\n        self.train = train\n        self.data = pd.read_csv(os.path.join(dataPath, 'IRSE_Training_Data_preprocessed.csv' if train else 'IRSE_Test_Data_preprocessed.csv'))\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        record = self.data.iloc[index]\n        text = \"[CLS] \" + record['Comments'] + \" [SEP] \"+record['Surrounding Code Context']\n        label = 0 if record['Class'] == 'Not Useful' else 1\n        return {'text': text, 'label': label}\n\ntrain_dataset = TweetDataset(train=True)\ntest_dataset = TweetDataset(train=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:31:28.011940Z","iopub.execute_input":"2022-08-07T06:31:28.012298Z","iopub.status.idle":"2022-08-07T06:31:28.068372Z","shell.execute_reply.started":"2022-08-07T06:31:28.012267Z","shell.execute_reply":"2022-08-07T06:31:28.067472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nif self.train:\n            return {'text': text, 'label': label}\n\n'''","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:31:29.189840Z","iopub.execute_input":"2022-08-07T06:31:29.190201Z","iopub.status.idle":"2022-08-07T06:31:29.195706Z","shell.execute_reply.started":"2022-08-07T06:31:29.190164Z","shell.execute_reply":"2022-08-07T06:31:29.194788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    print(train_dataset.__getitem__(i)['text'])","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:31:31.766609Z","iopub.execute_input":"2022-08-07T06:31:31.766944Z","iopub.status.idle":"2022-08-07T06:31:31.778121Z","shell.execute_reply.started":"2022-08-07T06:31:31.766913Z","shell.execute_reply":"2022-08-07T06:31:31.777224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BertClassificationCollator(object):\n    def __init__(self, tokenizer, max_seq_len=None):\n        self.tokenizer = tokenizer\n        self.max_seq_len = max_seq_len\n        \n        return\n    \n    def __call__(self, sequences):\n        texts = [sequence['text'] for sequence in sequences]\n        labels = [int(sequence['label']) for sequence in sequences]\n        inputs = self.tokenizer(text=texts,\n                                return_tensors='pt',\n                                padding=True,\n                                truncation=True,\n                                max_length=self.max_seq_len)\n        inputs.update({'labels': torch.tensor(labels)})\n        \n        return inputs\n\nBertClassificationCollator = BertClassificationCollator(tokenizer=tokenizer,\n                                                        max_seq_len=60)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:32:54.204088Z","iopub.execute_input":"2022-08-07T06:32:54.204419Z","iopub.status.idle":"2022-08-07T06:32:54.211755Z","shell.execute_reply.started":"2022-08-07T06:32:54.204388Z","shell.execute_reply":"2022-08-07T06:32:54.210799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\n\ntrain_size = int(len(train_dataset) * 0.8)\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\ntrain_dataloader = DataLoader(dataset=train_dataset,\n                              batch_size=32,\n                              shuffle=True,\n                              collate_fn=BertClassificationCollator)\nval_dataloader = DataLoader(dataset=val_dataset,\n                            batch_size=32,\n                            shuffle=False,\n                            collate_fn=BertClassificationCollator)\ntest_dataloader = DataLoader(dataset=test_dataset,\n                             batch_size=32,\n                             shuffle=False,\n                             collate_fn=BertClassificationCollator)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:33:01.577483Z","iopub.execute_input":"2022-08-07T06:33:01.577810Z","iopub.status.idle":"2022-08-07T06:33:01.585501Z","shell.execute_reply.started":"2022-08-07T06:33:01.577777Z","shell.execute_reply":"2022-08-07T06:33:01.584480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification, AdamW, BertConfig\n\n\nmodel = BertForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n    num_labels = 2, # The number of output labels--2 for binary classification.\n                    # You can increase this for multi-class tasks.   \n    output_attentions = False, # Whether the model returns attentions weights.\n    output_hidden_states = False, # Whether the model returns all hidden-states.\n)\n\n# Tell pytorch to run this model on the GPU.\nmodel.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:33:03.031414Z","iopub.execute_input":"2022-08-07T06:33:03.031750Z","iopub.status.idle":"2022-08-07T06:33:07.271463Z","shell.execute_reply.started":"2022-08-07T06:33:03.031716Z","shell.execute_reply":"2022-08-07T06:33:07.270545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get all of the model's parameters as a list of tuples.\nparams = list(model.named_parameters())\n\nprint('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n\nprint('==== Embedding Layer ====\\n')\n\nfor p in params[0:5]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n\nprint('\\n==== First Transformer ====\\n')\n\nfor p in params[5:21]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n\nprint('\\n==== Output Layer ====\\n')\n\nfor p in params[-4:]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:33:07.273182Z","iopub.execute_input":"2022-08-07T06:33:07.273705Z","iopub.status.idle":"2022-08-07T06:33:07.287863Z","shell.execute_reply.started":"2022-08-07T06:33:07.273664Z","shell.execute_reply":"2022-08-07T06:33:07.287084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n# I believe the 'W' stands for 'Weight Decay fix\"\noptimizer = AdamW(model.parameters(),\n                  lr = 5e-5, # args.learning_rate - default is 5e-5\n                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n                )","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:33:09.346337Z","iopub.execute_input":"2022-08-07T06:33:09.346661Z","iopub.status.idle":"2022-08-07T06:33:09.354188Z","shell.execute_reply.started":"2022-08-07T06:33:09.346625Z","shell.execute_reply":"2022-08-07T06:33:09.353142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import get_linear_schedule_with_warmup\n\n# Number of training epochs. The BERT authors recommend between 2 and 4. \n# We chose to run for 2,I have already seen that the model starts overfitting beyound 2 epochs\nepochs = 2\n\n# Total number of training steps is [number of batches] x [number of epochs]. \n# (Note that this is not the same as the number of training samples).\ntotal_steps = len(train_dataloader) * epochs\n\n# Create the learning rate scheduler.\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps = 0, # Default value in run_glue.py\n                                            num_training_steps = total_steps)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:33:14.101873Z","iopub.execute_input":"2022-08-07T06:33:14.102241Z","iopub.status.idle":"2022-08-07T06:33:14.108450Z","shell.execute_reply.started":"2022-08-07T06:33:14.102207Z","shell.execute_reply":"2022-08-07T06:33:14.107398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Function to calculate the accuracy of our predictions vs labels\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:33:20.233930Z","iopub.execute_input":"2022-08-07T06:33:20.234286Z","iopub.status.idle":"2022-08-07T06:33:20.241679Z","shell.execute_reply.started":"2022-08-07T06:33:20.234251Z","shell.execute_reply":"2022-08-07T06:33:20.240071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport datetime\n\ndef format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    \n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:35:00.401719Z","iopub.execute_input":"2022-08-07T06:35:00.402058Z","iopub.status.idle":"2022-08-07T06:35:00.407381Z","shell.execute_reply.started":"2022-08-07T06:35:00.402004Z","shell.execute_reply":"2022-08-07T06:35:00.406264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW, get_cosine_schedule_with_warmup\n\ntotal_epochs = 10\n\nparam_optimizer = list(model.named_parameters())\nno_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\noptimizer_grouped_parameters = [\n    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n]\noptimizer = AdamW(optimizer_grouped_parameters,\n                  lr=1e-5,\n                  eps=1e-8)\n\nnum_train_steps = len(train_dataloader) * total_epochs\nnum_warmup_steps = int(num_train_steps * 0.1) \n\nlr_scheduler = get_cosine_schedule_with_warmup(optimizer,\n                                               num_warmup_steps=num_warmup_steps,\n                                               num_training_steps = num_train_steps)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:35:07.467009Z","iopub.execute_input":"2022-08-07T06:35:07.467375Z","iopub.status.idle":"2022-08-07T06:35:07.481299Z","shell.execute_reply.started":"2022-08-07T06:35:07.467342Z","shell.execute_reply":"2022-08-07T06:35:07.480454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel.to(device)\n\nall_loss = {'train_loss': [], 'val_loss': []}\nall_acc = {'train_acc': [], 'val_acc': []}\n\nfor epoch in range(total_epochs):\n    y, y_pred, train_loss = train(train_dataloader, optimizer, lr_scheduler, device)\n    train_acc = accuracy_score(y, y_pred)\n    \n    y, y_pred, val_loss = validation(val_dataloader, device)\n    val_acc = accuracy_score(y, y_pred)\n    \n    all_loss['train_loss'] += train_loss\n    all_loss['val_loss'] += val_loss\n    \n    all_acc['train_acc'].append(train_acc)\n    all_acc['val_acc'].append(val_acc)\n    \n    print(f'Epoch: {epoch}, train_loss: {torch.tensor(train_loss).mean():.3f}, train_acc: {train_acc:.3f}, val_loss: {torch.tensor(val_loss).mean():.3f}, val_acc: {val_acc:.3f}') ","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:35:39.946873Z","iopub.execute_input":"2022-08-07T06:35:39.947225Z","iopub.status.idle":"2022-08-07T06:47:13.467863Z","shell.execute_reply.started":"2022-08-07T06:35:39.947192Z","shell.execute_reply":"2022-08-07T06:47:13.466949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfig = plt.figure(figsize=(20,20))\na = fig.add_subplot(4, 1, 1)\nb = fig.add_subplot(4, 1, 2)\nc = fig.add_subplot(2, 1, 2)\na.plot(all_loss['train_loss'])\nb.plot(all_loss['val_loss'])\nc.plot(all_acc['train_acc'])\nc.plot(all_acc['val_acc'])\nc.set(xlabel='epoch', ylabel='accuracy')\nc.legend(['train', 'val'])\n\npass","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:47:13.470358Z","iopub.execute_input":"2022-08-07T06:47:13.470887Z","iopub.status.idle":"2022-08-07T06:47:13.927829Z","shell.execute_reply.started":"2022-08-07T06:47:13.470842Z","shell.execute_reply":"2022-08-07T06:47:13.926980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y, y_pred, val_loss = validation(val_dataloader, device)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:47:13.929342Z","iopub.execute_input":"2022-08-07T06:47:13.929990Z","iopub.status.idle":"2022-08-07T06:47:22.142149Z","shell.execute_reply.started":"2022-08-07T06:47:13.929948Z","shell.execute_reply":"2022-08-07T06:47:22.141217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ntarget_names = ['Not Useful', 'Useful']\nprint(classification_report(y, y_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:47:22.143667Z","iopub.execute_input":"2022-08-07T06:47:22.144280Z","iopub.status.idle":"2022-08-07T06:47:22.162576Z","shell.execute_reply.started":"2022-08-07T06:47:22.144240Z","shell.execute_reply":"2022-08-07T06:47:22.161805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y, y_pred, val_loss = validation(test_dataloader, device)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:47:22.167264Z","iopub.execute_input":"2022-08-07T06:47:22.169181Z","iopub.status.idle":"2022-08-07T06:47:26.857012Z","shell.execute_reply.started":"2022-08-07T06:47:22.169143Z","shell.execute_reply":"2022-08-07T06:47:26.856241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ntarget_names = ['Not Useful', 'Useful']\nprint(classification_report(y, y_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:47:26.858373Z","iopub.execute_input":"2022-08-07T06:47:26.858691Z","iopub.status.idle":"2022-08-07T06:47:26.872807Z","shell.execute_reply.started":"2022-08-07T06:47:26.858656Z","shell.execute_reply":"2022-08-07T06:47:26.871841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, y_pred, _ = validation(test_dataloader, device)\n\nsubmit = pd.read_csv(dataPath+'IRSE_Test_Data_preprocessed.csv')\nsubmit['target'] = y_pred\n\nsubmit.to_csv('IRSE_Test_Data_preprocessed_BERT.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:47:26.874987Z","iopub.execute_input":"2022-08-07T06:47:26.875426Z","iopub.status.idle":"2022-08-07T06:47:31.560983Z","shell.execute_reply.started":"2022-08-07T06:47:26.875389Z","shell.execute_reply":"2022-08-07T06:47:31.560115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"bert_model\")","metadata":{"execution":{"iopub.status.busy":"2022-08-07T06:47:31.562370Z","iopub.execute_input":"2022-08-07T06:47:31.562720Z","iopub.status.idle":"2022-08-07T06:47:32.350430Z","shell.execute_reply.started":"2022-08-07T06:47:31.562682Z","shell.execute_reply":"2022-08-07T06:47:32.349608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}